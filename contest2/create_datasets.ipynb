{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_path = '/mnt/kaggle-made2/data/'\n",
    "train_file = os.path.join(data_path, 'train.json')\n",
    "train_seg_file = os.path.join(data_path, 'train_mask.json')\n",
    "train_rec_file = os.path.join(data_path, 'train_rec.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25633\n",
      "100 25633\n",
      "200 25633\n",
      "300 25633\n",
      "400 25633\n",
      "500 25633\n",
      "600 25633\n",
      "700 25633\n",
      "800 25633\n",
      "900 25633\n",
      "1000 25633\n",
      "1100 25633\n",
      "1200 25633\n",
      "1300 25633\n",
      "1400 25633\n",
      "1500 25633\n",
      "1600 25633\n",
      "1700 25633\n",
      "1800 25633\n",
      "1900 25633\n",
      "2000 25633\n",
      "2100 25633\n",
      "2200 25633\n",
      "2300 25633\n",
      "2400 25633\n",
      "2500 25633\n",
      "2600 25633\n",
      "2700 25633\n",
      "2800 25633\n",
      "2900 25633\n",
      "3000 25633\n",
      "3100 25633\n",
      "3200 25633\n",
      "3300 25633\n",
      "3400 25633\n",
      "3500 25633\n",
      "3600 25633\n",
      "3700 25633\n",
      "3800 25633\n",
      "3900 25633\n",
      "4000 25633\n",
      "4100 25633\n",
      "4200 25633\n",
      "4300 25633\n",
      "4400 25633\n",
      "4500 25633\n",
      "4600 25633\n",
      "4700 25633\n",
      "4800 25633\n",
      "4900 25633\n",
      "5000 25633\n",
      "5100 25633\n",
      "5200 25633\n",
      "5300 25633\n",
      "5400 25633\n",
      "5500 25633\n",
      "5600 25633\n",
      "5700 25633\n",
      "5800 25633\n",
      "5900 25633\n",
      "6000 25633\n",
      "6100 25633\n",
      "6200 25633\n",
      "6300 25633\n",
      "6400 25633\n",
      "6500 25633\n",
      "6600 25633\n",
      "6700 25633\n",
      "6800 25633\n",
      "6900 25633\n",
      "7000 25633\n",
      "7100 25633\n",
      "7200 25633\n",
      "7300 25633\n",
      "7400 25633\n",
      "7500 25633\n",
      "7600 25633\n",
      "7700 25633\n",
      "7800 25633\n",
      "7900 25633\n",
      "8000 25633\n",
      "8100 25633\n",
      "8200 25633\n",
      "8300 25633\n",
      "8400 25633\n",
      "8500 25633\n",
      "8600 25633\n",
      "8700 25633\n",
      "8800 25633\n",
      "8900 25633\n",
      "9000 25633\n",
      "9100 25633\n",
      "9200 25633\n",
      "9300 25633\n",
      "9400 25633\n",
      "9500 25633\n",
      "9600 25633\n",
      "9700 25633\n",
      "9800 25633\n",
      "9900 25633\n",
      "10000 25633\n",
      "10100 25633\n",
      "10200 25633\n",
      "10300 25633\n",
      "10400 25633\n",
      "10500 25633\n",
      "10600 25633\n",
      "10700 25633\n",
      "10800 25633\n",
      "10900 25633\n",
      "11000 25633\n",
      "11100 25633\n",
      "11200 25633\n",
      "11300 25633\n",
      "11400 25633\n",
      "11500 25633\n",
      "11600 25633\n",
      "11700 25633\n",
      "11800 25633\n",
      "11900 25633\n",
      "12000 25633\n",
      "12100 25633\n",
      "12200 25633\n",
      "12300 25633\n",
      "12400 25633\n",
      "12500 25633\n",
      "12600 25633\n",
      "12700 25633\n",
      "12800 25633\n",
      "12900 25633\n",
      "13000 25633\n",
      "13100 25633\n",
      "13200 25633\n",
      "13300 25633\n",
      "13400 25633\n",
      "13500 25633\n",
      "13600 25633\n",
      "13700 25633\n",
      "13800 25633\n",
      "13900 25633\n",
      "14000 25633\n",
      "14100 25633\n",
      "14200 25633\n",
      "14300 25633\n",
      "14400 25633\n",
      "14500 25633\n",
      "14600 25633\n",
      "14700 25633\n",
      "14800 25633\n",
      "14900 25633\n",
      "15000 25633\n",
      "15100 25633\n",
      "15200 25633\n",
      "15300 25633\n",
      "15400 25633\n",
      "15500 25633\n",
      "15600 25633\n",
      "15700 25633\n",
      "15800 25633\n",
      "15900 25633\n",
      "16000 25633\n",
      "16100 25633\n",
      "16200 25633\n",
      "16300 25633\n",
      "16400 25633\n",
      "16500 25633\n",
      "16600 25633\n",
      "16700 25633\n",
      "16800 25633\n",
      "16900 25633\n",
      "17000 25633\n",
      "17100 25633\n",
      "17200 25633\n",
      "17300 25633\n",
      "17400 25633\n",
      "17500 25633\n",
      "17600 25633\n",
      "17700 25633\n",
      "17800 25633\n",
      "17900 25633\n",
      "18000 25633\n",
      "18100 25633\n",
      "18200 25633\n",
      "18300 25633\n",
      "18400 25633\n",
      "18500 25633\n",
      "18600 25633\n",
      "18700 25633\n",
      "18800 25633\n",
      "18900 25633\n",
      "19000 25633\n",
      "19100 25633\n",
      "19200 25633\n",
      "19300 25633\n",
      "19400 25633\n",
      "19500 25633\n",
      "19600 25633\n",
      "19700 25633\n",
      "19800 25633\n",
      "19900 25633\n",
      "20000 25633\n",
      "20100 25633\n",
      "20200 25633\n",
      "20300 25633\n",
      "20400 25633\n",
      "20500 25633\n",
      "20600 25633\n",
      "20700 25633\n",
      "20800 25633\n",
      "20900 25633\n",
      "21000 25633\n",
      "21100 25633\n",
      "21200 25633\n",
      "21300 25633\n",
      "21400 25633\n",
      "21500 25633\n",
      "21600 25633\n",
      "21700 25633\n",
      "21800 25633\n",
      "21900 25633\n",
      "22000 25633\n",
      "22100 25633\n",
      "22200 25633\n",
      "22300 25633\n",
      "22400 25633\n",
      "22500 25633\n",
      "22600 25633\n",
      "22700 25633\n",
      "22800 25633\n",
      "22900 25633\n",
      "23000 25633\n",
      "23100 25633\n",
      "23200 25633\n",
      "23300 25633\n",
      "23400 25633\n",
      "23500 25633\n",
      "23600 25633\n",
      "23700 25633\n",
      "23800 25633\n",
      "23900 25633\n",
      "24000 25633\n",
      "24100 25633\n",
      "24200 25633\n",
      "24300 25633\n",
      "24400 25633\n",
      "24500 25633\n",
      "24600 25633\n",
      "24700 25633\n",
      "24800 25633\n",
      "24900 25633\n",
      "25000 25633\n",
      "25100 25633\n",
      "25200 25633\n",
      "25300 25633\n",
      "25400 25633\n",
      "25500 25633\n",
      "25600 25633\n"
     ]
    }
   ],
   "source": [
    "# Lets convert bounding boxes to segmentation masks, you can do it on the fly,\n",
    "# if you've got enough CPU and high num workers\n",
    "with open(train_file) as rf:\n",
    "    data = json.load(rf)\n",
    "\n",
    "for i, elem in enumerate(data):\n",
    "    if i % 100 == 0:\n",
    "        print (i, len(data))\n",
    "    fbase = elem['file']\n",
    "    fname = os.path.join(data_path, fbase)\n",
    "    base, ext = os.path.splitext(fbase)\n",
    "    mask_fname = base + '.mask' + ext\n",
    "    mask_path = os.path.join(data_path, mask_fname)\n",
    "    nums = elem['nums']\n",
    "\n",
    "    if not os.path.exists(mask_path):\n",
    "        img = cv2.imread(fname)\n",
    "        if img is None:\n",
    "            continue\n",
    "        mask = np.zeros(shape=img.shape, dtype=np.uint8)\n",
    "        for num in nums:\n",
    "            bbox = np.array(num['box'])\n",
    "            cv2.fillConvexPoly(mask, bbox, (255,255,255))\n",
    "        cv2.imwrite(mask_path, mask)\n",
    "\n",
    "    elem['mask'] = mask_fname\n",
    "\n",
    "with open(train_seg_file, 'w') as wf:\n",
    "    json.dump(data, wf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25632\n",
      "(3, 1396, 1733)\n",
      "(1396, 1733)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "from detection.dataset import DetectionDataset\n",
    "#\n",
    "dataset = DetectionDataset(data_path, config_file=train_seg_file)\n",
    "print(len(dataset))\n",
    "image, mask = dataset[0]\n",
    "print(image.shape)\n",
    "print(mask.shape)\n",
    "print(np.max(mask))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# generate ocr dataset\n",
    "if not os.path.exists(train_rec_file):\n",
    "    with open(train_file) as rf:\n",
    "        data = json.load(rf)\n",
    "\n",
    "    new_data = []\n",
    "    for i, elem in enumerate(data):\n",
    "        #if i % 100 == 0:\n",
    "        #    print (i, len(data))\n",
    "        img_path = os.path.join(data_path, elem['file'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        for j, true_box in enumerate(elem['nums']):\n",
    "            base, ext = os.path.splitext(elem['file'])\n",
    "            addon = base + '.box' + str(j) + ext\n",
    "            crop_name = os.path.join(data_path, addon)\n",
    "\n",
    "            box = true_box['box']\n",
    "            x_box = [w[0] for w in box]\n",
    "            y_box = [w[1] for w in box]\n",
    "            x1, x2 = max(0, min(x_box)), max(x_box)\n",
    "            y1, y2 = max(0, min(y_box)), max(y_box)\n",
    "            crop = img[y1: y2, x1: x2, :] #  TODO: you can normalize bounding box to make the OCR task easier\n",
    "            cv2.imwrite(crop_name, crop)\n",
    "\n",
    "            new_data.append(dict(file=addon, text=true_box['text']))\n",
    "        break\n",
    "    with open(train_rec_file, 'w') as wf:\n",
    "         json.dump(new_data, wf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 25300\n",
      "(167, 418, 3) B060BB125\n"
     ]
    }
   ],
   "source": [
    "import recognition\n",
    "sys.path.insert(0, recognition.__path__[0])\n",
    "from recognition.dataset import RecognitionDataset\n",
    "train_dataset = RecognitionDataset(data_path, train_rec_file)\n",
    "print('Train dataset: {}'.format(len(train_dataset)))\n",
    "print(train_dataset[0]['image'].shape, train_dataset[0]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HOHMH9Y9M9Y9H98H', 'HOHME8H8EH', 'HO8EHMHYMY98H', 'HOEHMHYEMP8', 'HO8HMHEYEY98E8', '8OHM8EYEMPYH98', '8O8H2MHYEYP8H', '8EH2MHEYEM4P9H9898', 'HO8H2MHEYEMEY8', 'HOHMEPH8EH', 'HOHMHYM4P8H']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from recognition.model import RecognitionModel\n",
    "model = RecognitionModel()\n",
    "model.eval()\n",
    "np.random.seed(0)\n",
    "inputs = torch.Tensor(np.random.normal(size=(11, 3, 32, 320)))\n",
    "outputs = model.forward(inputs, decode=True)\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}